{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_b_vecs = np.read_csv('./train_data/all_bs_matrix.csv',header = None)\n",
    "x = np.genfromtxt('./train_data/all_bs_matrix.csv', delimiter=\",\")\n",
    "y = np.genfromtxt('./train_data/all_mean_opt_beta.csv', delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(y, (-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.5895 - mse: 1.5895 - mae: 1.0328\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.2225 - mse: 1.2225 - mae: 0.9195\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 7.7991 - mse: 7.7991 - mae: 2.3182\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.6015 - mse: 1.6015 - mae: 1.0236\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.2632 - mse: 1.2632 - mae: 0.8592\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.6150 - mse: 1.6150 - mae: 0.9860\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.7481 - mse: 1.7481 - mae: 1.0159\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 71.4089 - mse: 71.4089 - mae: 8.3106\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 68.7941 - mse: 68.7941 - mae: 8.1424\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 45.3485 - mse: 45.3485 - mae: 6.5629\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 64.4396 - mse: 64.4396 - mae: 7.8494\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.6502 - mse: 1.6502 - mae: 0.9930\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 57.8569 - mse: 57.8569 - mae: 7.4623\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 46.9679 - mse: 46.9679 - mae: 6.7296\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 76.0060 - mse: 76.0060 - mae: 8.5888\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 52.2534 - mse: 52.2534 - mae: 7.0034\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 5.5439 - mse: 5.5439 - mae: 2.0606\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 59.3718 - mse: 59.3718 - mae: 7.5394\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 72.1866 - mse: 72.1866 - mae: 8.3208\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 1.6644 - mse: 1.6644 - mae: 1.0806\n",
      "\n",
      "\n",
      "Size of test set:  0.2 \n",
      "\n",
      "Train Loss:  [[ 0.99839123]\n",
      " [ 1.33577971]\n",
      " [ 8.98722786]\n",
      " [ 1.72601644]\n",
      " [ 1.40707825]\n",
      " [ 1.82108146]\n",
      " [ 1.17795361]\n",
      " [73.52822735]\n",
      " [72.4695816 ]\n",
      " [50.57282357]\n",
      " [66.90577075]\n",
      " [ 1.39326273]\n",
      " [65.07268113]\n",
      " [49.68987349]\n",
      " [75.58340253]\n",
      " [49.60615248]\n",
      " [ 2.95778735]\n",
      " [70.90713079]\n",
      " [70.41466151]\n",
      " [ 0.85492643]] \n",
      "\n",
      "Validation Loss: [[ 1.58954451]\n",
      " [ 1.22252418]\n",
      " [ 7.79905701]\n",
      " [ 1.60147066]\n",
      " [ 1.26320823]\n",
      " [ 1.61495016]\n",
      " [ 1.74807029]\n",
      " [71.40892639]\n",
      " [68.79410858]\n",
      " [45.34851913]\n",
      " [64.43961868]\n",
      " [ 1.65015168]\n",
      " [57.85688324]\n",
      " [46.96785431]\n",
      " [76.00597687]\n",
      " [52.25341873]\n",
      " [ 5.54389868]\n",
      " [59.37183304]\n",
      " [72.18663635]\n",
      " [ 1.66442676]]\n",
      "60/60 [==============================] - 0s 274us/sample - loss: 3.9201 - mse: 3.9201 - mae: 1.7099\n",
      "60/60 [==============================] - 0s 257us/sample - loss: 66.1690 - mse: 66.1690 - mae: 7.9886\n",
      "60/60 [==============================] - 0s 217us/sample - loss: 1.1459 - mse: 1.1459 - mae: 0.8848\n",
      "60/60 [==============================] - 0s 228us/sample - loss: 74.5021 - mse: 74.5021 - mae: 8.4807\n",
      "60/60 [==============================] - 0s 236us/sample - loss: 59.6304 - mse: 59.6304 - mae: 7.5857\n",
      "60/60 [==============================] - 0s 219us/sample - loss: 23.8384 - mse: 23.8384 - mae: 4.6131\n",
      "60/60 [==============================] - 0s 218us/sample - loss: 43.9609 - mse: 43.9609 - mae: 6.4373\n",
      "60/60 [==============================] - 0s 220us/sample - loss: 5.1140 - mse: 5.1140 - mae: 1.9569\n",
      "60/60 [==============================] - 0s 370us/sample - loss: 59.3058 - mse: 59.3058 - mae: 7.4998\n",
      "60/60 [==============================] - 0s 219us/sample - loss: 82.0003 - mse: 82.0003 - mae: 8.8988\n",
      "60/60 [==============================] - 0s 227us/sample - loss: 71.4546 - mse: 71.4546 - mae: 8.3218\n",
      "60/60 [==============================] - 0s 225us/sample - loss: 73.0626 - mse: 73.0626 - mae: 8.4206\n",
      "60/60 [==============================] - 0s 234us/sample - loss: 71.3201 - mse: 71.3201 - mae: 8.2931\n",
      "60/60 [==============================] - 0s 222us/sample - loss: 3.2981 - mse: 3.2981 - mae: 1.4240\n",
      "60/60 [==============================] - 0s 219us/sample - loss: 16.0599 - mse: 16.0599 - mae: 3.1190\n",
      "60/60 [==============================] - 0s 229us/sample - loss: 3.0921 - mse: 3.0921 - mae: 1.4192\n",
      "60/60 [==============================] - 0s 250us/sample - loss: 4.6679 - mse: 4.6679 - mae: 1.7382\n",
      "60/60 [==============================] - 0s 284us/sample - loss: 6.1081 - mse: 6.1081 - mae: 2.2519\n",
      "60/60 [==============================] - 0s 245us/sample - loss: 68.6956 - mse: 68.6956 - mae: 8.1759\n",
      "60/60 [==============================] - 0s 217us/sample - loss: 57.8848 - mse: 57.8848 - mae: 7.4514\n",
      "\n",
      "\n",
      "Size of test set:  0.3 \n",
      "\n",
      "Train Loss:  [[ 2.36107153]\n",
      " [66.75091553]\n",
      " [ 1.20517102]\n",
      " [69.27134561]\n",
      " [57.44180874]\n",
      " [23.39286685]\n",
      " [44.08182703]\n",
      " [ 2.27691449]\n",
      " [53.46991267]\n",
      " [79.92539387]\n",
      " [72.57321178]\n",
      " [81.81711401]\n",
      " [69.91179565]\n",
      " [ 1.13459065]\n",
      " [10.1956724 ]\n",
      " [ 3.27112108]\n",
      " [ 2.99728923]\n",
      " [ 2.40847232]\n",
      " [73.04085392]\n",
      " [55.33568108]] \n",
      "\n",
      "Validation Loss: [[ 3.9200734 ]\n",
      " [66.16901652]\n",
      " [ 1.14592938]\n",
      " [74.50208028]\n",
      " [59.63037974]\n",
      " [23.83835716]\n",
      " [43.96087087]\n",
      " [ 5.11398271]\n",
      " [59.30583827]\n",
      " [82.00025126]\n",
      " [71.45464579]\n",
      " [73.06258036]\n",
      " [71.32009226]\n",
      " [ 3.29805576]\n",
      " [16.05988045]\n",
      " [ 3.09209541]\n",
      " [ 4.66793162]\n",
      " [ 6.10812438]\n",
      " [68.69564514]\n",
      " [57.88479131]]\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 1.6001 - mse: 1.6001 - mae: 1.1039\n",
      "80/80 [==============================] - 0s 298us/sample - loss: 2.4918 - mse: 2.4918 - mae: 1.4049\n",
      "80/80 [==============================] - 0s 245us/sample - loss: 1.6237 - mse: 1.6237 - mae: 0.9849\n",
      "80/80 [==============================] - 0s 251us/sample - loss: 1.2308 - mse: 1.2308 - mae: 0.8137\n",
      "80/80 [==============================] - 0s 252us/sample - loss: 10.3046 - mse: 10.3046 - mae: 3.1078\n",
      "80/80 [==============================] - 0s 294us/sample - loss: 52.4736 - mse: 52.4736 - mae: 7.0628\n",
      "80/80 [==============================] - 0s 221us/sample - loss: 1.5849 - mse: 1.5849 - mae: 1.0469\n",
      "80/80 [==============================] - 0s 227us/sample - loss: 21.7696 - mse: 21.7696 - mae: 4.3828\n",
      "80/80 [==============================] - 0s 227us/sample - loss: 48.1542 - mse: 48.1542 - mae: 6.7591\n",
      "80/80 [==============================] - 0s 241us/sample - loss: 5.1537 - mse: 5.1537 - mae: 1.9151\n",
      "80/80 [==============================] - 0s 246us/sample - loss: 1.3927 - mse: 1.3927 - mae: 0.9007\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 2.1782 - mse: 2.1782 - mae: 1.0892\n",
      "80/80 [==============================] - 0s 229us/sample - loss: 74.5189 - mse: 74.5189 - mae: 8.4930\n",
      "80/80 [==============================] - 0s 277us/sample - loss: 2.4884 - mse: 2.4884 - mae: 1.3795\n",
      "80/80 [==============================] - 0s 241us/sample - loss: 86.7915 - mse: 86.7915 - mae: 9.1631\n",
      "80/80 [==============================] - 0s 228us/sample - loss: 1.6777 - mse: 1.6777 - mae: 1.1347\n",
      "80/80 [==============================] - 0s 255us/sample - loss: 11.1348 - mse: 11.1348 - mae: 2.9536\n",
      "80/80 [==============================] - 0s 217us/sample - loss: 77.1321 - mse: 77.1321 - mae: 8.6521\n",
      "80/80 [==============================] - 0s 240us/sample - loss: 4.6949 - mse: 4.6949 - mae: 1.8542\n",
      "80/80 [==============================] - 0s 255us/sample - loss: 75.0706 - mse: 75.0706 - mae: 8.5053\n",
      "\n",
      "\n",
      "Size of test set:  0.4 \n",
      "\n",
      "Train Loss:  [[ 1.77422556]\n",
      " [ 1.36030452]\n",
      " [ 1.2395045 ]\n",
      " [ 0.9778794 ]\n",
      " [ 2.82717899]\n",
      " [48.0338197 ]\n",
      " [ 0.97795878]\n",
      " [25.13168728]\n",
      " [51.07458851]\n",
      " [ 1.63216682]\n",
      " [ 1.44379134]\n",
      " [ 4.47228629]\n",
      " [75.19512966]\n",
      " [ 1.76575915]\n",
      " [81.99615786]\n",
      " [ 1.7766706 ]\n",
      " [11.07055457]\n",
      " [77.05537682]\n",
      " [ 4.63793682]\n",
      " [70.79790249]] \n",
      "\n",
      "Validation Loss: [[ 1.60010161]\n",
      " [ 2.49180193]\n",
      " [ 1.62374594]\n",
      " [ 1.23083853]\n",
      " [10.30455837]\n",
      " [52.47362518]\n",
      " [ 1.58493848]\n",
      " [21.76961288]\n",
      " [48.15422363]\n",
      " [ 5.1537056 ]\n",
      " [ 1.39271191]\n",
      " [ 2.1781631 ]\n",
      " [74.51887817]\n",
      " [ 2.48836288]\n",
      " [86.79149933]\n",
      " [ 1.67769499]\n",
      " [11.13479958]\n",
      " [77.13206177]\n",
      " [ 4.69487963]\n",
      " [75.07060852]]\n",
      "100/100 [==============================] - 0s 255us/sample - loss: 40.6456 - mse: 40.6456 - mae: 6.1505\n",
      "100/100 [==============================] - 0s 285us/sample - loss: 83.5770 - mse: 83.5770 - mae: 9.0047\n",
      "100/100 [==============================] - 0s 235us/sample - loss: 78.7164 - mse: 78.7164 - mae: 8.7296\n",
      "100/100 [==============================] - 0s 210us/sample - loss: 83.3867 - mse: 83.3867 - mae: 8.9988\n",
      "100/100 [==============================] - 0s 251us/sample - loss: 46.0378 - mse: 46.0378 - mae: 6.5892\n",
      "100/100 [==============================] - 0s 249us/sample - loss: 77.9511 - mse: 77.9511 - mae: 8.6943\n",
      "100/100 [==============================] - 0s 267us/sample - loss: 81.2117 - mse: 81.2117 - mae: 8.8805\n",
      "100/100 [==============================] - 0s 241us/sample - loss: 83.8036 - mse: 83.8036 - mae: 9.0037\n",
      "100/100 [==============================] - 0s 268us/sample - loss: 34.9768 - mse: 34.9768 - mae: 5.7018\n",
      "100/100 [==============================] - 0s 280us/sample - loss: 1.6555 - mse: 1.6555 - mae: 0.9777\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 76.4900 - mse: 76.4900 - mae: 8.5865\n",
      "100/100 [==============================] - 0s 274us/sample - loss: 1.4271 - mse: 1.4271 - mae: 0.9650\n",
      "100/100 [==============================] - 0s 243us/sample - loss: 8.9299 - mse: 8.9299 - mae: 2.5796\n",
      "100/100 [==============================] - 0s 229us/sample - loss: 13.2603 - mse: 13.2603 - mae: 2.7615\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 19.5618 - mse: 19.5618 - mae: 3.9217\n",
      "100/100 [==============================] - 0s 240us/sample - loss: 83.9453 - mse: 83.9453 - mae: 9.0365\n",
      "100/100 [==============================] - 0s 255us/sample - loss: 80.8642 - mse: 80.8642 - mae: 8.8406\n",
      "100/100 [==============================] - 0s 259us/sample - loss: 73.5124 - mse: 73.5124 - mae: 8.4315\n",
      "100/100 [==============================] - 0s 196us/sample - loss: 3.4176 - mse: 3.4176 - mae: 1.5564\n",
      "100/100 [==============================] - 0s 255us/sample - loss: 2.9916 - mse: 2.9916 - mae: 1.5048\n",
      "\n",
      "\n",
      "Size of test set:  0.5 \n",
      "\n",
      "Train Loss:  [[37.4886108 ]\n",
      " [83.58181811]\n",
      " [75.02583189]\n",
      " [89.21574787]\n",
      " [39.30399029]\n",
      " [79.83813701]\n",
      " [81.29032906]\n",
      " [84.68821082]\n",
      " [37.41885521]\n",
      " [ 1.64692121]\n",
      " [75.22452762]\n",
      " [ 1.60955621]\n",
      " [ 3.29377585]\n",
      " [ 2.99933989]\n",
      " [14.1428454 ]\n",
      " [79.43365856]\n",
      " [82.70461261]\n",
      " [73.01328583]\n",
      " [10.37095673]\n",
      " [ 1.3721548 ]] \n",
      "\n",
      "Validation Loss: [[40.64558693]\n",
      " [83.57701965]\n",
      " [78.71642151]\n",
      " [83.38673218]\n",
      " [46.03783417]\n",
      " [77.95105652]\n",
      " [81.2117276 ]\n",
      " [83.80358612]\n",
      " [34.97677902]\n",
      " [ 1.65550388]\n",
      " [76.49002167]\n",
      " [ 1.42713606]\n",
      " [ 8.92993572]\n",
      " [13.26031174]\n",
      " [19.56182167]\n",
      " [83.94534424]\n",
      " [80.86415314]\n",
      " [73.51237   ]\n",
      " [ 3.41764978]\n",
      " [ 2.99158998]]\n",
      "120/120 [==============================] - 0s 802us/sample - loss: 54.0064 - mse: 54.0064 - mae: 7.1463\n",
      "120/120 [==============================] - 0s 692us/sample - loss: 45.1592 - mse: 45.1592 - mae: 6.5237\n",
      "120/120 [==============================] - 0s 672us/sample - loss: 3.1098 - mse: 3.1098 - mae: 1.5728\n",
      "120/120 [==============================] - 0s 693us/sample - loss: 49.4821 - mse: 49.4821 - mae: 6.5368\n",
      "120/120 [==============================] - 0s 689us/sample - loss: 4.9443 - mse: 4.9443 - mae: 1.8545\n",
      "120/120 [==============================] - 0s 689us/sample - loss: 82.5541 - mse: 82.5541 - mae: 8.9537\n",
      "120/120 [==============================] - 0s 697us/sample - loss: 2.2563 - mse: 2.2563 - mae: 1.1130\n",
      "120/120 [==============================] - 0s 656us/sample - loss: 2.9938 - mse: 2.9938 - mae: 1.4867\n",
      "120/120 [==============================] - 0s 713us/sample - loss: 83.5718 - mse: 83.5718 - mae: 8.9935\n",
      "120/120 [==============================] - 0s 747us/sample - loss: 86.7249 - mse: 86.7249 - mae: 9.1763\n",
      "120/120 [==============================] - 0s 683us/sample - loss: 77.0009 - mse: 77.0009 - mae: 8.6348\n",
      "120/120 [==============================] - 0s 694us/sample - loss: 6.3958 - mse: 6.3958 - mae: 2.1879\n",
      "120/120 [==============================] - 0s 644us/sample - loss: 82.2054 - mse: 82.2054 - mae: 8.9147\n",
      "120/120 [==============================] - 0s 674us/sample - loss: 80.8647 - mse: 80.8647 - mae: 8.8505\n",
      "120/120 [==============================] - 0s 664us/sample - loss: 2.1562 - mse: 2.1562 - mae: 1.2015\n",
      "120/120 [==============================] - 0s 720us/sample - loss: 1.3613 - mse: 1.3613 - mae: 0.9093\n",
      "120/120 [==============================] - 0s 685us/sample - loss: 2.6645 - mse: 2.6645 - mae: 1.4387\n",
      "120/120 [==============================] - 0s 690us/sample - loss: 1.5318 - mse: 1.5318 - mae: 1.0105\n",
      "120/120 [==============================] - 0s 692us/sample - loss: 81.5370 - mse: 81.5370 - mae: 8.8948\n",
      "120/120 [==============================] - 0s 726us/sample - loss: 1.3776 - mse: 1.3776 - mae: 0.9266\n",
      "\n",
      "\n",
      "Size of test set:  0.6 \n",
      "\n",
      "Train Loss:  [[53.78954616]\n",
      " [44.36680653]\n",
      " [ 1.32090641]\n",
      " [13.0880898 ]\n",
      " [76.15398248]\n",
      " [90.64954055]\n",
      " [ 1.11517286]\n",
      " [ 2.29886097]\n",
      " [79.56489302]\n",
      " [82.73323139]\n",
      " [85.52007816]\n",
      " [ 3.75480845]\n",
      " [79.7110144 ]\n",
      " [78.82636402]\n",
      " [ 4.39985457]\n",
      " [ 1.38714523]\n",
      " [ 1.46105826]\n",
      " [ 1.06783479]\n",
      " [86.59741412]\n",
      " [ 1.04397699]] \n",
      "\n",
      "Validation Loss: [[54.00638072]\n",
      " [45.15922038]\n",
      " [ 3.10976055]\n",
      " [49.4821078 ]\n",
      " [ 4.94429146]\n",
      " [82.55411631]\n",
      " [ 2.2562669 ]\n",
      " [ 2.99382463]\n",
      " [83.57178446]\n",
      " [86.72486369]\n",
      " [77.00094452]\n",
      " [ 6.39580873]\n",
      " [82.20544027]\n",
      " [80.86466064]\n",
      " [ 2.15622795]\n",
      " [ 1.36128855]\n",
      " [ 2.66451073]\n",
      " [ 1.53175656]\n",
      " [81.53699087]\n",
      " [ 1.37763646]]\n",
      "140/140 [==============================] - 0s 222us/sample - loss: 81.2912 - mse: 81.2912 - mae: 8.8669\n",
      "140/140 [==============================] - 0s 235us/sample - loss: 9.4047 - mse: 9.4047 - mae: 2.4689\n",
      "140/140 [==============================] - 0s 220us/sample - loss: 77.9825 - mse: 77.9825 - mae: 8.6791\n",
      "140/140 [==============================] - 0s 248us/sample - loss: 2.7219 - mse: 2.7219 - mae: 1.4538\n",
      "140/140 [==============================] - 0s 253us/sample - loss: 86.9118 - mse: 86.9118 - mae: 9.1854\n",
      "140/140 [==============================] - 0s 233us/sample - loss: 81.9619 - mse: 81.9619 - mae: 8.9013\n",
      "140/140 [==============================] - 0s 270us/sample - loss: 2.7710 - mse: 2.7710 - mae: 1.3778\n",
      "140/140 [==============================] - 0s 264us/sample - loss: 81.9014 - mse: 81.9014 - mae: 8.8995\n",
      "140/140 [==============================] - 0s 273us/sample - loss: 85.7441 - mse: 85.7441 - mae: 9.1244\n",
      "140/140 [==============================] - 0s 206us/sample - loss: 6.0641 - mse: 6.0641 - mae: 2.2802\n",
      "140/140 [==============================] - 0s 242us/sample - loss: 1.4130 - mse: 1.4130 - mae: 0.9905\n",
      "140/140 [==============================] - 0s 254us/sample - loss: 1.9710 - mse: 1.9710 - mae: 1.2332\n",
      "140/140 [==============================] - 0s 288us/sample - loss: 2.4658 - mse: 2.4658 - mae: 1.3900\n",
      "140/140 [==============================] - 0s 239us/sample - loss: 56.5816 - mse: 56.5816 - mae: 7.3405\n",
      "140/140 [==============================] - 0s 225us/sample - loss: 1.5515 - mse: 1.5515 - mae: 1.0544\n",
      "140/140 [==============================] - 0s 241us/sample - loss: 1.5443 - mse: 1.5443 - mae: 0.9809\n",
      "140/140 [==============================] - 0s 221us/sample - loss: 89.8581 - mse: 89.8581 - mae: 9.3401\n",
      "140/140 [==============================] - 0s 229us/sample - loss: 81.2349 - mse: 81.2349 - mae: 8.8813\n",
      "140/140 [==============================] - 0s 229us/sample - loss: 23.5082 - mse: 23.5082 - mae: 4.3082\n",
      "140/140 [==============================] - 0s 236us/sample - loss: 2.4498 - mse: 2.4498 - mae: 1.3874\n",
      "\n",
      "\n",
      "Size of test set:  0.7 \n",
      "\n",
      "Train Loss:  [[84.78334601]\n",
      " [ 5.22476954]\n",
      " [71.57795635]\n",
      " [ 1.22960627]\n",
      " [88.54250971]\n",
      " [80.72124702]\n",
      " [ 1.98432652]\n",
      " [81.78813867]\n",
      " [92.38706448]\n",
      " [ 1.54768094]\n",
      " [ 1.38173189]\n",
      " [ 1.6627713 ]\n",
      " [ 2.1941854 ]\n",
      " [56.81585265]\n",
      " [ 1.63862207]\n",
      " [ 1.04083612]\n",
      " [89.96549533]\n",
      " [90.43510517]\n",
      " [ 4.29146975]\n",
      " [ 3.17499834]] \n",
      "\n",
      "Validation Loss: [[81.29121421]\n",
      " [ 9.40465405]\n",
      " [77.98245043]\n",
      " [ 2.72187348]\n",
      " [86.91176932]\n",
      " [81.96191777]\n",
      " [ 2.77104094]\n",
      " [81.90137743]\n",
      " [85.74413343]\n",
      " [ 6.06405134]\n",
      " [ 1.41303721]\n",
      " [ 1.97102332]\n",
      " [ 2.46577205]\n",
      " [56.58164193]\n",
      " [ 1.55148581]\n",
      " [ 1.54428436]\n",
      " [89.85814972]\n",
      " [81.23487091]\n",
      " [23.50816656]\n",
      " [ 2.44976194]]\n",
      "160/160 [==============================] - 0s 532us/sample - loss: 7.9418 - mse: 7.9418 - mae: 2.4085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 526us/sample - loss: 88.3684 - mse: 88.3684 - mae: 9.2560\n",
      "160/160 [==============================] - 0s 520us/sample - loss: 85.2133 - mse: 85.2133 - mae: 9.0950\n",
      "160/160 [==============================] - 0s 532us/sample - loss: 82.2189 - mse: 82.2189 - mae: 8.9218\n",
      "160/160 [==============================] - 0s 523us/sample - loss: 90.0743 - mse: 90.0743 - mae: 9.3541\n",
      "160/160 [==============================] - 0s 495us/sample - loss: 90.0391 - mse: 90.0391 - mae: 9.3481\n",
      "160/160 [==============================] - 0s 524us/sample - loss: 1.6734 - mse: 1.6734 - mae: 0.9552\n",
      "160/160 [==============================] - 0s 533us/sample - loss: 87.2527 - mse: 87.2527 - mae: 9.2096\n",
      "160/160 [==============================] - 0s 531us/sample - loss: 1.5007 - mse: 1.5007 - mae: 0.9364\n",
      "160/160 [==============================] - 0s 2ms/sample - loss: 5.5204 - mse: 5.5204 - mae: 2.0505\n",
      "160/160 [==============================] - 0s 493us/sample - loss: 88.1810 - mse: 88.1810 - mae: 9.2550\n",
      "160/160 [==============================] - 0s 528us/sample - loss: 1.4865 - mse: 1.4865 - mae: 1.0091\n",
      "160/160 [==============================] - 0s 533us/sample - loss: 89.4206 - mse: 89.4206 - mae: 9.3222\n",
      "160/160 [==============================] - 0s 488us/sample - loss: 91.9601 - mse: 91.9601 - mae: 9.4437\n",
      "160/160 [==============================] - 0s 521us/sample - loss: 12.4363 - mse: 12.4363 - mae: 2.7741\n",
      "160/160 [==============================] - 0s 517us/sample - loss: 88.6433 - mse: 88.6433 - mae: 9.2751\n",
      "160/160 [==============================] - 0s 528us/sample - loss: 89.6021 - mse: 89.6021 - mae: 9.3269\n",
      "160/160 [==============================] - 0s 515us/sample - loss: 84.2548 - mse: 84.2548 - mae: 9.0428\n",
      "160/160 [==============================] - 0s 495us/sample - loss: 17.6223 - mse: 17.6223 - mae: 3.7268\n",
      "160/160 [==============================] - 0s 503us/sample - loss: 91.0283 - mse: 91.0283 - mae: 9.3810\n",
      "\n",
      "\n",
      "Size of test set:  0.8 \n",
      "\n",
      "Train Loss:  [[ 8.84183199]\n",
      " [84.93271798]\n",
      " [86.14962166]\n",
      " [80.41738209]\n",
      " [76.89263836]\n",
      " [93.50647495]\n",
      " [ 1.31632326]\n",
      " [85.89541385]\n",
      " [ 1.34046927]\n",
      " [ 4.75320696]\n",
      " [84.41350756]\n",
      " [ 1.06640893]\n",
      " [85.08557089]\n",
      " [86.47463307]\n",
      " [ 8.12779058]\n",
      " [85.80106675]\n",
      " [91.19963797]\n",
      " [91.69325417]\n",
      " [ 9.49668835]\n",
      " [87.4159823 ]] \n",
      "\n",
      "Validation Loss: [[ 7.94175072]\n",
      " [88.36838531]\n",
      " [85.21332397]\n",
      " [82.21890259]\n",
      " [90.07427368]\n",
      " [90.03908386]\n",
      " [ 1.67343509]\n",
      " [87.25268097]\n",
      " [ 1.50070736]\n",
      " [ 5.52035742]\n",
      " [88.18103333]\n",
      " [ 1.48648125]\n",
      " [89.42058105]\n",
      " [91.96014252]\n",
      " [12.43632622]\n",
      " [88.64329071]\n",
      " [89.60209503]\n",
      " [84.2547699 ]\n",
      " [17.6223423 ]\n",
      " [91.02828674]]\n",
      "180/180 [==============================] - 0s 170us/sample - loss: 93.1441 - mse: 93.1441 - mae: 9.5169\n",
      "180/180 [==============================] - 0s 202us/sample - loss: 91.7525 - mse: 91.7525 - mae: 9.4388\n",
      "180/180 [==============================] - 0s 214us/sample - loss: 10.8192 - mse: 10.8192 - mae: 2.9253\n",
      "180/180 [==============================] - 0s 206us/sample - loss: 94.0737 - mse: 94.0737 - mae: 9.5627\n",
      "180/180 [==============================] - 0s 211us/sample - loss: 1.3611 - mse: 1.3611 - mae: 0.9309\n",
      "180/180 [==============================] - 0s 206us/sample - loss: 91.7094 - mse: 91.7094 - mae: 9.4172\n",
      "180/180 [==============================] - 0s 217us/sample - loss: 3.3911 - mse: 3.3911 - mae: 1.4651\n",
      "180/180 [==============================] - 0s 203us/sample - loss: 93.5497 - mse: 93.5497 - mae: 9.5421\n",
      "180/180 [==============================] - 0s 210us/sample - loss: 3.0052 - mse: 3.0052 - mae: 1.4198\n",
      "180/180 [==============================] - 0s 231us/sample - loss: 92.0094 - mse: 92.0094 - mae: 9.4573\n",
      "180/180 [==============================] - 0s 203us/sample - loss: 96.1621 - mse: 96.1621 - mae: 9.6783\n",
      "180/180 [==============================] - 0s 296us/sample - loss: 90.3007 - mse: 90.3007 - mae: 9.3678\n",
      "180/180 [==============================] - 0s 219us/sample - loss: 88.7184 - mse: 88.7184 - mae: 9.2805\n",
      "180/180 [==============================] - 0s 217us/sample - loss: 92.8885 - mse: 92.8885 - mae: 9.5047\n",
      "180/180 [==============================] - 0s 240us/sample - loss: 94.1495 - mse: 94.1495 - mae: 9.5671\n",
      "180/180 [==============================] - 0s 249us/sample - loss: 91.6473 - mse: 91.6473 - mae: 9.4313\n",
      "180/180 [==============================] - 0s 220us/sample - loss: 93.8129 - mse: 93.8129 - mae: 9.5506\n",
      "180/180 [==============================] - 0s 220us/sample - loss: 1.3795 - mse: 1.3795 - mae: 0.9280\n",
      "180/180 [==============================] - 0s 225us/sample - loss: 1.4312 - mse: 1.4312 - mae: 0.9395\n",
      "180/180 [==============================] - 0s 234us/sample - loss: 3.5386 - mse: 3.5386 - mae: 1.2494\n",
      "\n",
      "\n",
      "Size of test set:  0.9 \n",
      "\n",
      "Train Loss:  [[ 91.73942325]\n",
      " [ 94.17275158]\n",
      " [ 21.95556365]\n",
      " [ 92.25265222]\n",
      " [  1.23541492]\n",
      " [ 95.97007551]\n",
      " [  0.85345148]\n",
      " [100.81957807]\n",
      " [  3.45608526]\n",
      " [ 84.95907151]\n",
      " [ 87.61778862]\n",
      " [ 93.32450746]\n",
      " [ 89.07782183]\n",
      " [ 82.78744145]\n",
      " [ 82.44645611]\n",
      " [ 84.29022498]\n",
      " [ 83.93569665]\n",
      " [  1.60634466]\n",
      " [  0.84145412]\n",
      " [  1.38801754]] \n",
      "\n",
      "Validation Loss: [[93.1441001 ]\n",
      " [91.75248871]\n",
      " [10.81917631]\n",
      " [94.0737303 ]\n",
      " [ 1.36113497]\n",
      " [91.70941128]\n",
      " [ 3.39113943]\n",
      " [93.54969042]\n",
      " [ 3.00516478]\n",
      " [92.00942756]\n",
      " [96.16213057]\n",
      " [90.30065545]\n",
      " [88.71844516]\n",
      " [92.88854133]\n",
      " [94.14945577]\n",
      " [91.64725901]\n",
      " [93.81289012]\n",
      " [ 1.3794654 ]\n",
      " [ 1.43118797]\n",
      " [ 3.53861515]]\n"
     ]
    }
   ],
   "source": [
    "numTrials = 20\n",
    "splits = [.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "\n",
    "for ii in splits:\n",
    "    \n",
    "    trainLoss = np.zeros((numTrials,1))\n",
    "    scoreVec = np.zeros((numTrials,1))\n",
    "\n",
    "    for jj in range(0,numTrials):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=ii)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=50000, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=4,  verbose=0, validation_split=0.05)\n",
    "        trainLoss[jj] = history.history['loss'][49]        \n",
    "        scoreVec[jj] = model.evaluate(X_test,y_test)[0]\n",
    "        del model\n",
    "\n",
    "    print('\\n\\nSize of test set: ', ii,'\\n\\nTrain Loss: ',trainLoss,'\\n\\nValidation Loss:',scoreVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
